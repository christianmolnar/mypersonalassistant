import { Agent, AgentTask, AgentTaskResult } from './Agent';
import fs from 'fs/promises';
import path from 'path';
import axios from 'axios';
import * as cheerio from 'cheerio';
import { AI_CONFIG } from './ai_config';
import puppeteer from 'puppeteer';

export class ResearcherAgent implements Agent {
  id = 'researcher';
  name = 'Personal Researcher Agent';
  description = 'Conducts research, summarizes findings, and performs fact-checking using trusted resources.';
  abilities = [
    'Conduct Personal Topic Research',
    'Summarize Personal Findings',
    'Generate Personal Reference Lists',
    'Compare Products/Services',
    'Find Resources for Hobbies, Health, Travel, etc.',
    'Monitor Trends/News in Personal Interest Areas',
    'Draft Personal Project Reports or Summaries',
    'Research news and identify misinformation',
    'Perform fact-checking research using the integrated cheat sheet and online tools'
  ];

  // I'll add a helper to robustly extract a decision from an LLM answer
  private extractDecision(text: string | null | undefined): string {
    if (!text) return 'Uncertain';
    const lower = text.toLowerCase();
    // Strong negation patterns
    if (/\b(false|no|incorrect|inaccurate|myth|hoax|fake|refuted|contradicts|not true|not correct|not accurate|the statement is false|is not|are not|does not|cannot be|never)\b/.test(lower)) {
      return 'False';
    }
    // Strong affirmation patterns
    if (/\b(true|yes|correct|accurate|fact|the statement is true|is correct|is true|are true|is accurate|is a fact)\b/.test(lower)) {
      return 'True';
    }
    if (/\b(uncertain|unknown|unclear|cannot determine|not sure|ambiguous|mixed|disputed)\b/.test(lower)) return 'Uncertain';
    // Fallback: check for explicit contradiction in the first sentence
    const firstSentence = lower.split(/[.!?]/)[0];
    if (/not|never|no evidence|refuted|contradicts/.test(firstSentence)) return 'False';
    // Fallback: first word logic
    const firstWord = lower.split(/\W+/)[0];
    if (["true","false","uncertain","yes","no"].includes(firstWord)) {
      if (firstWord === "yes") return "True";
      if (firstWord === "no") return "False";
      return firstWord.charAt(0).toUpperCase() + firstWord.slice(1);
    }
    return 'Uncertain';
  }

  // I'll add a helper to extract a decision from a Wikipedia or Google summary
  private extractDecisionFromSummary(claim: string, summary: string | null | undefined): string {
    if (!summary) return 'Uncertain';
    const claimLower = claim.toLowerCase();
    const summaryLower = summary.toLowerCase();
    // I'll try to extract the subject and role from the claim
    // e.g., "Kamala Harris is President of the US"
    const officeMatch = claim.match(/([\w .'-]+) is (the )?([\w ]+) of ([\w .'-]+)/i);
    if (officeMatch) {
      const subject = officeMatch[1].trim().toLowerCase();
      const role = officeMatch[3].trim().toLowerCase();
      const entity = officeMatch[4].trim().toLowerCase();
      if (summaryLower.includes(subject) && summaryLower.includes(role)) {
        if (role === 'president' && summaryLower.includes('vice president')) return 'False';
        if (role === 'prime minister' && summaryLower.includes('deputy prime minister')) return 'False';
        const presidentMatch = summaryLower.match(/under president ([\w .'-]+)/);
        if (role === 'president' && presidentMatch && !presidentMatch[1].includes(subject)) return 'False';
        if (summaryLower.includes('served as') && summaryLower.includes(role)) return 'True';
        if ((summaryLower.includes('current') || summaryLower.includes('is the')) && summaryLower.includes(role)) return 'True';
        return 'Uncertain';
      }
      if (summaryLower.includes(subject) && !summaryLower.includes(role)) {
        if (role === 'president' && summaryLower.includes('vice president')) return 'False';
        return 'Uncertain';
      }
      const otherPersonMatch = summaryLower.match(new RegExp(`${role} of ${entity}.*?([\w .'-]+)`, 'i'));
      if (otherPersonMatch && !otherPersonMatch[1].includes(subject)) return 'False';
    }
    // I'll handle location/property claims: "X is in Y", "X was built in Y", "X has Y"
    const inMatch = claim.match(/([\w .'-]+) is in ([\w .'-]+)/i);
    if (inMatch) {
      const subject = inMatch[1].trim().toLowerCase();
      const location = inMatch[2].trim().toLowerCase();
      if (summaryLower.includes(subject) && summaryLower.includes(location)) return 'True';
      if (summaryLower.includes(subject) && !summaryLower.includes(location)) return 'False';
    }
    const builtMatch = claim.match(/([\w .'-]+) was built in ([\w .'-]+)/i);
    if (builtMatch) {
      const subject = builtMatch[1].trim().toLowerCase();
      const year = builtMatch[2].trim();
      if (summaryLower.includes(subject) && summaryLower.includes(year)) return 'True';
      if (summaryLower.includes(subject) && /\d{4}/.test(year) && !summaryLower.includes(year)) return 'False';
    }
    // I'll handle numeric/date claims: "X was released in 2023", "X has Y property"
    const dateMatch = claim.match(/([\w .'-]+) (was released|was built|was born|was established|occurred) in (\d{4})/i);
    if (dateMatch) {
      const subject = dateMatch[1].trim().toLowerCase();
      const year = dateMatch[3];
      if (summaryLower.includes(subject) && summaryLower.includes(year)) return 'True';
      if (summaryLower.includes(subject) && !summaryLower.includes(year)) return 'False';
    }
    // I'll handle property claims: "Water boils at 100°C"
    const propertyMatch = claim.match(/([\w .'-]+) (boils at|freezes at|melts at|has a mass of|has a length of|has a population of) ([\d.,°cF]+)/i);
    if (propertyMatch) {
      const subject = propertyMatch[1].trim().toLowerCase();
      const property = propertyMatch[2].trim().toLowerCase();
      const value = propertyMatch[3].trim().toLowerCase();
      if (summaryLower.includes(subject) && summaryLower.includes(value)) return 'True';
      if (summaryLower.includes(subject) && !summaryLower.includes(value)) return 'False';
    }
    // Fallback: if summary directly negates the claim
    if (/not|never|no evidence|disputed|hoax|fake/.test(summaryLower)) return 'False';
    // If summary affirms the claim
    if (/is the|currently|serves as|served as/.test(summaryLower) && summaryLower.includes(claimLower.split(' is ')[0])) return 'True';
    // If summary contains the main subject and at least one key word from the claim, and no contradiction, return 'True'
    const subjectWord = claimLower.split(' ')[0];
    if (summaryLower.includes(subjectWord)) {
      const claimWords = claimLower.split(' ').filter(w => w.length > 3);
      let matchCount = 0;
      for (const w of claimWords) {
        if (summaryLower.includes(w)) matchCount++;
      }
      if (matchCount >= 2) return 'True';
    }
    return 'Uncertain';
  }

  async handleTask(task: AgentTask): Promise<AgentTaskResult> {
    if (task.type === 'fact_check_text') {
      const claim = task.payload?.claim;
      if (!claim) return { success: false, result: null, error: 'No claim provided.' };

      // I'll define common Wikipedia-first patterns
      const wikiPatterns = [
        /who\s+is\s+the\s+president\b/i,
        /current\s+president\b/i,
        /who\s+is\s+the\s+prime\s+minister\b/i,
        /current\s+prime\s+minister\b/i,
        /who\s+is\s+the\s+king\b/i,
        /current\s+king\b/i,
        /who\s+is\s+the\s+queen\b/i,
        /current\s+queen\b/i,
        /who\s+is\s+the\s+governor\b/i,
        /current\s+governor\b/i,
        /who\s+is\s+the\s+mayor\b/i,
        /current\s+mayor\b/i,
        /who\s+is\s+the\s+leader\b/i,
        /current\s+leader\b/i,
        /who\s+is\s+the\s+ceo\b/i,
        /current\s+ceo\b/i,
        /what\s+is\s+the\s+population\b/i,
        /current\s+population\b/i,
        /what\s+is\s+the\s+capital\b/i,
        /current\s+capital\b/i,
        /when\s+was\s+.*\s+founded\b/i,
        /when\s+was\s+.*\s+established\b/i,
        /when\s+was\s+.*\s+born\b/i,
        /when\s+did\s+.*\s+die\b/i,
        /when\s+did\s+.*\s+occur\b/i,
        /what\s+is\s+the\s+area\b/i,
        /current\s+area\b/i,
        /what\s+is\s+the\s+gdp\b/i,
        /current\s+gdp\b/i,
        /what\s+is\s+the\s+currency\b/i,
        /current\s+currency\b/i,
        // I'll add a generic pattern for 'X is president of Y' and similar
        /is\s+.*president\s+of\s+/i,
        /is\s+.*prime\s+minister\s+of\s+/i,
        /is\s+.*king\s+of\s+/i,
        /is\s+.*queen\s+of\s+/i,
        /is\s+.*mayor\s+of\s+/i,
        /is\s+.*governor\s+of\s+/i,
        /is\s+.*ceo\s+of\s+/i,
        /is\s+.*capital\s+of\s+/i,
        /is\s+.*currency\s+of\s+/i,
        /is\s+.*population\s+of\s+/i,
        /is\s+.*gdp\s+of\s+/i
      ];
      let useWikipedia = wikiPatterns.some((pat) => pat.test(claim));
      let wikiSubject: string | null = null;
      // I'll use LLM-based semantic detection if no pattern matched
      if (!useWikipedia) {
        try {
          const today = new Date().toISOString().split('T')[0];
          const llmRes = await axios.post(
            AI_CONFIG.llm.endpoint,
            {
              model: AI_CONFIG.llm.model,
              messages: [
                { role: 'system', content: `You are a world-class fact-checking assistant. Today is ${today}. I want you to classify the following claim. If it is a common fact (such as about a country's leader, capital, population, area, GDP, or currency), respond with 'YES' and the type (e.g., leader, capital, population, etc.) and the subject (e.g., country or entity). If not, respond with 'NO'.` },
                { role: 'user', content: `Claim: ${claim}` }
              ]
            },
            { headers: { 'Authorization': `Bearer ${AI_CONFIG.llm.apiKey}` } }
          );
          const llmText = llmRes.data.choices?.[0]?.message?.content || '';
          if (/^YES/i.test(llmText)) {
            useWikipedia = true;
            // I'll try to extract the subject from the LLM response (e.g., 'YES, leader, United States')
            const parts = llmText.split(',').map((s: string) => s.trim());
            if (parts.length >= 3) {
              wikiSubject = parts.slice(2).join(', '); // Handles commas in country/entity names
            } else if (parts.length === 2) {
              wikiSubject = parts[1];
            }
          }
        } catch (err) {
          // I'll ignore LLM errors for semantic detection and fallback to default
        }
      }
      let wikiResult: any = null;
      let googleResult: any = null;
      let llmResult: any = null;
      // Wikipedia logic
      if (useWikipedia) {
        let wikiTitle = '';
        if (wikiSubject) {
          wikiTitle = wikiSubject;
        } else if (/president.*united states|united states.*president/i.test(claim)) wikiTitle = 'President of the United States';
        else if (/prime minister.*united kingdom|united kingdom.*prime minister/i.test(claim)) wikiTitle = 'Prime Minister of the United Kingdom';
        else if (/president.*france|france.*president/i.test(claim)) wikiTitle = 'President of France';
        else if (/prime minister.*canada|canada.*prime minister/i.test(claim)) wikiTitle = 'Prime Minister of Canada';
        if (!wikiTitle) wikiTitle = claim;
        try {
          const searchRes = await axios.get(`https://en.wikipedia.org/w/rest.php/v1/search/title?q=${encodeURIComponent(wikiTitle)}&limit=1`);
          const page = searchRes.data.pages?.[0];
          let pageTitle = page?.title || wikiTitle;
          const summaryRes = await axios.get(`https://en.wikipedia.org/api/rest_v1/page/summary/${encodeURIComponent(pageTitle)}`);
          const summary = summaryRes.data;
          wikiResult = {
            summary: summary.extract,
            pageTitle,
            wikipediaUrl: summary.content_urls?.desktop?.page || `https://en.wikipedia.org/wiki/${encodeURIComponent(pageTitle)}`,
            primarySource: 'Wikipedia',
          };
        } catch (err: any) {
          wikiResult = null;
        }
      }
      // Google (SerpAPI) logic
      if (AI_CONFIG.serpApi.apiKey) {
        try {
          const serpRes = await axios.get(
            `${AI_CONFIG.serpApi.endpoint}?q=${encodeURIComponent(claim)}&api_key=${AI_CONFIG.serpApi.apiKey}&hl=en&gl=us`
          );
          const serpData = serpRes.data;
          let snippet = '';
          if (serpData.answer_box && serpData.answer_box.answer) {
            snippet = serpData.answer_box.answer;
          } else if (serpData.answer_box && serpData.answer_box.snippet) {
            snippet = serpData.answer_box.snippet;
          } else if (serpData.organic_results && serpData.organic_results.length > 0) {
            snippet = serpData.organic_results[0].snippet || serpData.organic_results[0].title;
          }
          if (snippet) {
            googleResult = {
              summary: snippet,
              googleSearch: `https://www.google.com/search?q=${encodeURIComponent(claim)}`,
              primarySource: 'Google',
            };
          }
        } catch (serpErr) {
          googleResult = null;
        }
      }
      // LLM logic (always get an answer for synthesis)
      let llmInitialAnswer = null;
      let llmInitialDecision = 'Undetermined';
      try {
        const today = new Date().toISOString().split('T')[0];
        const openaiRes = await axios.post(
          AI_CONFIG.llm.endpoint,
          {
            model: AI_CONFIG.llm.model,
            messages: [
              { role: 'system', content: `You are a world-class fact-checking assistant. Today is ${today}. Always answer with "True", "False", or "Uncertain" and a brief explanation. If the claim is about a political office, always cite the current officeholder as of today.` },
              { role: 'user', content: `Is this statement true as of today (${today}): "${claim}"?` }
            ]
          },
          { headers: { 'Authorization': `Bearer ${AI_CONFIG.llm.apiKey}` } }
        );
        llmInitialAnswer = openaiRes.data.choices?.[0]?.message?.content || '';
        llmResult = {
          summary: llmInitialAnswer,
          primarySource: 'OpenAI',
        };
      } catch (err: any) {
        llmResult = null;
      }
      // Synthesis logic: if there is disagreement or ambiguity, ask the LLM to synthesize
      let synthesizedDecision = null;
      if ((wikiResult && googleResult && wikiResult.summary !== googleResult.summary) || (!wikiResult && googleResult && llmResult) || (!wikiResult && !googleResult && llmResult)) {
        try {
          const synthesisPrompt = [
            'Given the following answers from different sources, synthesize the most likely correct answer and explain why.\n',
            wikiResult ? `Wikipedia: ${wikiResult.summary}` : '',
            googleResult ? `Google: ${googleResult.summary}` : '',
            llmResult ? `OpenAI: ${llmResult.summary}` : '',
          ].filter(Boolean).join('\n');
          const synthRes = await axios.post(
            AI_CONFIG.llm.endpoint,
            {
              model: AI_CONFIG.llm.model,
              messages: [
                { role: 'system', content: 'You are a world-class fact-checking assistant. Synthesize a final answer from the following sources.' },
                { role: 'user', content: synthesisPrompt }
              ]
            },
            { headers: { 'Authorization': `Bearer ${AI_CONFIG.llm.apiKey}` } }
          );
          synthesizedDecision = synthRes.data.choices?.[0]?.message?.content || null;
        } catch (err) {
          synthesizedDecision = null;
        }
      }
      // Compose the result object for the UI
      let decision: string;
      let primarySource = wikiResult ? 'Wikipedia' : (googleResult ? 'Google' : 'OpenAI');
      let summary = wikiResult?.summary || googleResult?.summary || llmResult?.summary || 'No answer found.';
      // If there is disagreement or synthesis was used, prefer the synthesized answer
      if (synthesizedDecision) {
        decision = this.extractDecision(synthesizedDecision);
        summary = synthesizedDecision;
        primarySource = 'Synthesis';
      } else if (wikiResult && wikiResult.summary) {
        decision = this.extractDecisionFromSummary(claim, wikiResult.summary);
        primarySource = 'Wikipedia';
        summary = wikiResult.summary;
      } else if (googleResult && googleResult.summary) {
        decision = this.extractDecisionFromSummary(claim, googleResult.summary);
        primarySource = 'Google';
        summary = googleResult.summary;
      } else {
        let decisionSource = llmInitialAnswer;
        decision = this.extractDecision(decisionSource);
        primarySource = 'OpenAI';
        summary = llmInitialAnswer || 'No answer found.';
      }
      let resultObj: any = {
        sources: {
          wikipedia: wikiResult,
          google: googleResult,
          openai: llmResult,
        },
        synthesizedDecision,
        primarySource,
        summary,
        wikipediaUrl: wikiResult?.wikipediaUrl,
        googleSearch: googleResult?.googleSearch || `https://www.google.com/search?q=${encodeURIComponent(claim)}`,
        decision, // I'll always include the parsed decision
      };
      return { success: true, result: resultObj };
    }
    if (task.type === 'fact_check_image') {
      // I'll scaffold image fact-checking support
      const imageUrl = task.payload?.imageUrl;
      if (!imageUrl) {
        return { success: false, result: null, error: 'No image URL or file provided.' };
      }
      // I'll return a placeholder response with TODOs for each challenge
      return {
        success: true,
        result: {
          summary: 'Image fact-checking is in development. Here is how I will approach it:',
          categories: [
            {
              type: 'Objects/People',
              todo: 'Check authenticity (altered, deepfake, etc.), context, provenance, and run reverse image search.'
            },
            {
              type: 'Image with Caption',
              todo: 'Extract and fact-check overlaid text (OCR), check if caption matches image, and detect misleading/fake captions.'
            },
            {
              type: 'Image of Text',
              todo: 'Extract text (OCR), verify source, and fact-check the extracted claim.'
            },
            {
              type: 'Image of Article',
              todo: 'Verify publication authenticity, detect alterations, and check source trustworthiness.'
            }
          ],
          guidance: 'For now, try a reverse image search (Google, Tineye) and use OCR tools to extract any text for fact-checking.',
          imageUrl
        }
      };
    }
    if (task.type === 'fact_check_url') {
      // I'll scaffold URL/article fact-checking support
      const url = task.payload?.url;
      const claim = task.payload?.claim;
      if (!url) {
        return { success: false, result: null, error: 'No URL provided.' };
      }
      // TODO: Fetch the article/site, extract main text, and summarize/extract main claim(s)
      // For now, return a placeholder response
      return {
        success: true,
        result: {
          summary: 'URL/article fact-checking is in development. I will fetch the article, extract the main claim(s), and run them through the fact-checking pipeline.',
          url,
          claim,
          guidance: 'For now, manually review the article and paste the main claim for fact-checking.'
        }
      };
    }    if (task.type === 'fetch_webpage_text') {
      const url = task.payload?.url;
      console.log('[ResearcherAgent] fetch_webpage_text handler called for URL:', url);
      if (!url) {
        console.log('[ResearcherAgent] Returning: No URL provided.');
        return { success: false, result: null, error: 'No URL provided.' };
      }

      // Content validation helper
      function validateContent(text: string): boolean {
        // More lenient sentence detection
        const sentenceCount = (text.match(/[.!?]+\s+[A-Z]/g) || []).length + 1;
        const hasQuotes = (text.match(/["""'']/g) || []).length > 1;
        const hasLinks = text.includes('http') || text.includes('www');
        const hasNumbers = (text.match(/\d+/g) || []).length > 0;
        
        // Word count estimation (rough)
        const wordCount = text.split(/\s+/).length;
        
        return (
          // Standard article-length content
          (text.length >= 200 && sentenceCount >= 2) ||
          // Or meaningful quotes with some context
          (hasQuotes && text.length >= 100) ||
          // Or links with descriptive text
          (hasLinks && text.length >= 100) ||
          // Or text with numbers (likely meaningful data)
          (hasNumbers && text.length >= 100) ||
          // Or just substantial text
          wordCount >= 40
        );
      }

      // Puppeteer extraction with improved error handling
      async function extractWithPuppeteerInternal(): Promise<{success: boolean, text?: string, error?: string, fallbackHtml?: string}> {
        let currStep = 'init';
        let browser = null;
        let page = null;
        try {
          let executablePath = undefined;
          if (process.platform === 'win32') {
            currStep = 'resolve executablePath';
            executablePath = process.env.PUPPETEER_EXECUTABLE_PATH;
            if (!executablePath) {
              // Try common Chrome locations
              const commonPaths = [
                path.join(process.env.ProgramFiles || '', 'Google/Chrome/Application/chrome.exe'),
                path.join(process.env['ProgramFiles(x86)'] || '', 'Google/Chrome/Application/chrome.exe'),
                path.join(process.env.LOCALAPPDATA || '', 'Google/Chrome/Application/chrome.exe')
              ];
              for (const chromePath of commonPaths) {
                try {
                  await fs.access(chromePath);
                  executablePath = chromePath;
                  break;
                } catch (e) {
                  console.warn(`[Puppeteer] Chrome not found at: ${chromePath}`);
                }
              }
            }
          }

          currStep = 'launch browser';
          browser = await puppeteer.launch({ 
            headless: true,
            args: [
              '--no-sandbox', 
              '--disable-setuid-sandbox',
              '--disable-dev-shm-usage',
              '--disable-accelerated-2d-canvas',
              '--disable-gpu',
              '--window-size=1920,1080',
              '--disable-web-security', // For some paywalled sites
              '--disable-features=IsolateOrigins,site-per-process' // For some dynamic sites
            ],
            executablePath,
            timeout: 60000
          });

          currStep = 'new page';
          page = await browser.newPage();
          await page.setViewport({ width: 1920, height: 1080 });
          await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36');
          await page.setRequestInterception(true);

          page.on('request', (request) => {
            if (
              request.resourceType() === 'image' ||
              request.resourceType() === 'stylesheet' ||
              request.resourceType() === 'font' ||
              request.url().includes('google-analytics') ||
              request.url().includes('doubleclick') ||
              request.url().includes('facebook') ||
              request.url().includes('tracking') ||
              request.url().includes('advertising')
            ) {
              request.abort();
            } else {
              request.continue();
            }
          });

          currStep = 'goto';
          await Promise.race([
            page.goto(url, { waitUntil: 'networkidle0', timeout: 30000 }),
            new Promise((_, reject) => setTimeout(() => reject(new Error('Navigation timeout')), 30000))
          ]);

          // Wait a bit for dynamic content
          await new Promise(resolve => setTimeout(resolve, 2000));

          currStep = 'handle popups';
          try {
            await page.evaluate(() => {
              const selectors = [
                '[id*="cookie" i] button',
                '[class*="cookie" i] button',
                '[id*="consent" i] button',
                '[class*="consent" i] button',
                '[id*="popup" i] button',
                '[class*="popup" i] button',
                'button:not([hidden])',
                '[role="button"]'
              ];
              for (const selector of selectors) {
                document.querySelectorAll(selector).forEach(el => {
                  if (
                    el.textContent && 
                    /accept|agree|continue|ok|got it|i understand/i.test(el.textContent) &&
                    (el as HTMLElement).style.display !== 'none' &&
                    (el as HTMLElement).offsetHeight > 0
                  ) {
                    (el as HTMLElement).click();
                  }
                });
              }
            });
          } catch (popupErr) {
            console.warn('[Puppeteer] Error handling popups:', popupErr);
          }

          await new Promise(resolve => setTimeout(resolve, 1000));

          currStep = 'extract text';
          const extractResult = await page.evaluate(() => {
            document.querySelectorAll('nav, header, footer, aside, [role="navigation"], .nav, .navigation, .menu, .sidebar, .ad, .advertisement, .social-share, .comments, script, style, iframe')
              .forEach(el => el.remove());

            function preprocessText(text: string): string {
              return text
                .replace(/\s+/g, ' ')
                .replace(/\\n|\\r|\\t/g, ' ')
                .replace(/\u00A0/g, ' ')
                .replace(/\u2028|\u2029/g, '\n')
                .trim();
            }

            let bestContent = '';
            let bestScore = 0;

            // First try standard article selectors
            const contentSelectors = [
              'article', '[role="article"]', '.article',
              '.post-content', '.entry-content', '.content',
              'main', '#main-content', '.main-content',
              '.article-body', '.post-body', '.story-content',
              '[itemprop="articleBody"]', '[itemprop="text"]'
            ];

            for (const selector of contentSelectors) {
              const elements = document.querySelectorAll(selector);
              elements.forEach(el => {
                const text = preprocessText(el.textContent || '');
                if (text.length < 100) return;

                const paragraphs = Array.from(el.querySelectorAll('p'))
                  .map(p => preprocessText(p.textContent || ''))
                  .filter(t => t.length > 0);

                let score = text.length * 0.1;
                score += paragraphs.length * 15;
                score += (text.match(/[.!?]+/g) || []).length * 3;
                score += (text.match(/["""'']/g) || []).length;
                score += (text.match(/\d{4}/g) || []).length * 2;
                score += (text.match(/[A-Z][a-z]+\s+[A-Z][a-z]+/g) || []).length * 2;

                // Boost score for elements with semantic HTML
                if (el.matches('article, [itemprop="articleBody"], [itemprop="text"]')) {
                  score *= 1.5;
                }

                // Look for metadata that suggests real article content
                if (el.querySelector('time, [datetime], .date, .timestamp, .article-date')) {
                  score *= 1.3;
                }

                // Penalize navigation/ad content
                score -= (text.match(/cookie|privacy|advertisement|subscribe|sign up/gi) || []).length * 10;
                score -= (text.match(/newsletter|subscription|special offer/gi) || []).length * 8;

                // Penalize link-heavy sections
                const links = el.querySelectorAll('a');
                let linkTextLength = 0;
                links.forEach(link => {
                  linkTextLength += (link.textContent || '').length;
                  if (/home|about|contact|sign in|log in/i.test(link.textContent || '')) {
                    score -= 25;
                  }
                });
                if (linkTextLength) {
                  score -= (linkTextLength / text.length) * 30;
                }

                const content = paragraphs.length > 0 ? paragraphs.join('\n\n') : text;
                if (score > bestScore) {
                  bestScore = score;
                  bestContent = content;
                }
              });
            }

            // If no luck with article elements, try div-based heuristics
            if (!bestContent) {
              document.querySelectorAll('div').forEach(el => {
                const text = preprocessText(el.textContent || '');
                if (text.length < 100) return;

                const paragraphs = Array.from(el.querySelectorAll('p'))
                  .map(p => preprocessText(p.textContent || ''))
                  .filter(t => t.length > 0);

                let score = text.length * 0.05;
                score += (paragraphs.length * 10);

                // Same scoring rules as above...
                if (score > bestScore) {
                  bestScore = score;
                  bestContent = paragraphs.length > 0 ? paragraphs.join('\n\n') : text;
                }
              });
            }

            return { text: bestContent };
          });

          await browser.close();
          browser = null;

          if (extractResult.text) {
            console.log('[ResearcherAgent] Puppeteer extraction successful');
            return { success: true, text: extractResult.text };
          }

          return { 
            success: false, 
            error: 'Content validation failed: insufficient content length or structure',
            fallbackHtml: await page.content()
          };

        } catch (err: any) {
          console.error(`[Puppeteer fetch error at step: ${currStep}]`, err);

          let fallbackHtml = '';
          try {
            if (page) {
              fallbackHtml = await page.content();
            }
          } catch (fallbackErr) {
            console.error('[Puppeteer] Error getting fallback HTML:', fallbackErr);
          }

          return { 
            success: false, 
            error: `Puppeteer error at ${currStep}: ${err.message || err}`,
            fallbackHtml
          };

        } finally {
          if (browser) {
            try {
              await browser.close();
            } catch (closeErr) {
              console.error('[Puppeteer] Error closing browser:', closeErr);
            }
          }
        }
      }

      // Cheerio extraction with improved error handling
      async function extractWithCheerioInternal(html?: string): Promise<{success: boolean, text?: string, error?: string}> {
        try {
          console.log('[Cheerio] Starting extraction...');
          let $ = null;
          
          if (html) {
            $ = cheerio.load(html);
          } else {
            const response = await axios.get(url, {
              headers: {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br'
              },
              timeout: 15000,
              maxRedirects: 5
            });
            $ = cheerio.load(response.data);
          }

          // Remove non-content elements
          $('nav, header, footer, aside, .nav, .navigation, .menu, .sidebar, .ad, .advertisement, .social-share, .comments, script, style, iframe, meta, link').remove();

          let mainText = '';
          const selectors = [
            'article', '[role="article"]', '.article',
            '.post-content', '.entry-content', '.content',
            'main', '#main-content', '.main-content',
            '.article-body', '.post-body', '.story-content',
            '.story-body', '.news-article', '.wysiwyg_content',
            '.article__content', '#article-content',
            '[itemprop="articleBody"]', '[itemprop="text"]',
            '.article__body', '.article-text',
            '.story__content', '.article__main',
            '.article-body__content', '.article__content'
          ];

          // Try each selector in order of preference
          for (const selector of selectors) {
            const $content = $(selector);
            if ($content.length) {
              // Get all paragraphs and their text
              const paragraphs = $content.find('p').map((_, el) => {
                // Clean up the text
                return $(el).text()
                  .replace(/\s+/g, ' ')
                  .replace(/\\n|\\r|\\t/g, ' ')
                  .replace(/\u00A0/g, ' ')
                  .trim();
              }).get().filter(text => text.length > 0);

              if (paragraphs.length) {
                const text = paragraphs.join('\n\n');
                if (text.length > mainText.length) {
                  mainText = text;
                }
              }
            }
          }

          // If no luck with main selectors, try divs with substantial content
          if (!mainText) {
            let maxLen = 0;
            $('div').each((_, el) => {
              const $div = $(el);
              const paragraphs = $div.find('p').map((_, p) => $(p).text().trim()).get();
              const text = paragraphs.length ? paragraphs.join('\n\n') : $div.text().trim();
              
              // Basic scoring
              let score = text.length;
              score += (text.match(/[.!?]+/g) || []).length * 3;
              score += (text.match(/["""'']/g) || []).length;
              score -= (text.match(/cookie|privacy|advertisement|subscribe|sign up/gi) || []).length * 10;
              
              if (score > maxLen) {
                maxLen = score;
                mainText = text.replace(/\s+/g, ' ').trim();
              }
            });
          }

          if (validateContent(mainText)) {
            console.log('[Cheerio] Extraction successful');
            return { success: true, text: mainText };
          }

          console.log('[Cheerio] Extracted content failed validation');
          return { success: false, error: 'Insufficient content extracted with Cheerio' };

        } catch (err: any) {
          console.error('[Cheerio fetch error]', err);
          return { success: false, error: `Cheerio error: ${err.message || err}` };
        }
      }

      // Try Puppeteer first
      console.log('[ResearcherAgent] Attempting Puppeteer extraction...');
      const puppeteerResult = await extractWithPuppeteerInternal();
      if (puppeteerResult.success && puppeteerResult.text) {
        console.log('[ResearcherAgent] Puppeteer extraction successful');
        return { success: true, result: { text: puppeteerResult.text }};
      }

      // If Puppeteer failed but got HTML, try Cheerio with that HTML first
      console.log('[ResearcherAgent] Puppeteer failed, error:', puppeteerResult.error);
      if (puppeteerResult.fallbackHtml) {
        console.log('[ResearcherAgent] Trying Cheerio with Puppeteer HTML...');
        const cheerioResult = await extractWithCheerioInternal(puppeteerResult.fallbackHtml);
        if (cheerioResult.success && cheerioResult.text) {
          console.log('[ResearcherAgent] Cheerio extraction from Puppeteer HTML successful');
          return { success: true, result: { text: cheerioResult.text }};
        }
      }

      // Finally try Cheerio with fresh fetch
      console.log('[ResearcherAgent] Trying Cheerio with fresh fetch...');
      const cheerioResult = await extractWithCheerioInternal();
      if (cheerioResult.success && cheerioResult.text) {
        console.log('[ResearcherAgent] Cheerio extraction successful');
        return { success: true, result: { text: cheerioResult.text }};
      }

      // Both failed
      const errorMsg = `Failed to extract content: Puppeteer (${puppeteerResult.error}), Cheerio (${cheerioResult.error})`;
      console.error('[ResearcherAgent] Both extractors failed:', errorMsg);
      return { 
        success: false, 
        result: null, 
        error: errorMsg
      };
    }
    if (task.type === 'extract_claims_from_text') {
      const text = task.payload?.text;
      const url = task.payload?.url;
      
      if (!text) {
        return { success: false, result: null, error: 'No text provided for claim extraction.' };
      }

      try {
        const openaiRes = await axios.post(
          AI_CONFIG.llm.endpoint,
          {
            model: AI_CONFIG.llm.model,
            messages: [
              { 
                role: 'system', 
                content: `You are a claim extraction expert. Your task is to extract factual claims from text that can be fact-checked.

Rules:
1. Focus on specific, verifiable claims
2. Ignore opinions and subjective statements
3. Prioritize claims about events, statistics, quotes, or facts
4. Format your response EXACTLY like this example:
{
  "claims": [
    "The president announced a $5 billion infrastructure plan on June 1st",
    "Unemployment dropped to 4.2% in May",
    "The bill passed with 67 votes in favor"
  ]
}` 
              },
              { 
                role: 'user', 
                content: `Extract factual claims from this text and return them in the specified JSON format.\n\nSource URL: ${url}\n\nText: ${text}`
              }
            ]
          },
          { headers: { 'Authorization': `Bearer ${AI_CONFIG.llm.apiKey}` } }
        );

        const llmResponse = openaiRes.data.choices?.[0]?.message?.content;
        console.log('LLM claim extraction response:', llmResponse);

        let extractedClaims: string[] = [];

        try {
          // Try to parse as JSON with claims array
          const parsed = JSON.parse(llmResponse);
          if (parsed && Array.isArray(parsed.claims)) {
            extractedClaims = parsed.claims;
          } else if (Array.isArray(parsed)) {
            extractedClaims = parsed;
          }
        } catch (parseErr) {
          console.log('JSON parse failed, trying text extraction:', parseErr);
          // If not JSON, try to extract claims from plain text
          const textClaims = llmResponse
            .split(/\d+\.|[\n\r]+/)
            .map((s: string) => s.trim())
            .filter((s: string) => s.length > 0 && !s.startsWith('{') && !s.startsWith('}') && !s.includes('"claims":'));

          if (textClaims.length > 0) {
            extractedClaims = textClaims;
          }
        }

        if (extractedClaims.length > 0) {
          return {
            success: true,
            result: {
              claims: extractedClaims,
              mainClaim: extractedClaims[0] // Ensure mainClaim is always set to first claim
            }
          };
        }

        return {
          success: false,
          result: null,
          error: 'Could not extract any claims from the text'
        };

      } catch (err: any) {
        console.error('Error extracting claims:', err);
        return {
          success: false,
          result: null,
          error: `Error extracting claims: ${err.message || err}`
        };
      }
    }
    // I'll return a default error if the task type is not handled
    return { success: false, result: null, error: 'Unsupported task type.' };
  }
}
